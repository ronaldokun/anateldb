{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80feb396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| default_exp main\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Insert in Path Project Directory\n",
    "sys.path.insert(0, str(Path().cwd().parent))\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06a9485",
   "metadata": {},
   "source": [
    "# Principal\n",
    "> Este m√≥dulo concentra fun√ß√µes auxiliares espec√≠ficas que filtram os dados do banco com campos e formata√ß√£o de interesse para aplica√ß√µes espec√≠ficas como o [appAnalise](https://github.com/EricMagalhaesDelgado/appAnalise) por exemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac0c52ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| export\n",
    "from pathlib import Path\n",
    "import json\n",
    "from typing import Union\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "from fastcore.test import *\n",
    "from rich import print\n",
    "import pyodbc\n",
    "from pymongo import MongoClient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from extracao.constants import APP_ANALISE\n",
    "from extracao.reading import read_base, read_aero\n",
    "from extracao.format import merge_close_rows\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51124784",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def bump_version(\n",
    "    version: str,  # String com a vers√£o atual\n",
    "    part: int = 2,  # Parte da vers√£o que ser√° incrementada\n",
    ") -> str:  # Retorna a vers√£o atualizada\n",
    "    version = version.split(\".\")\n",
    "    version[part] = str(int(version[part]) + 1)\n",
    "    for i in range(part + 1, 3):\n",
    "        version[i] = \"0\"\n",
    "    return \".\".join(version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a3b2ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_modtimes(\n",
    "    pasta: Union[str, Path],  # Pasta onde est√£o os arquivos esperados de monitoramento\n",
    ") -> dict:  # Retorna o mtime de todos os arquivos pertinentes da pasta\n",
    "    \"\"\"\n",
    "    Retorna a data de modifica√ß√£o dos arquivos de dados contidos na pasta\n",
    "    \"\"\"\n",
    "    # Pasta\n",
    "    pasta = Path(pasta)\n",
    "    if not pasta.is_dir():\n",
    "        raise FileNotFoundError(f\"Pasta {pasta} n√£o encontrada\")\n",
    "    # Arquivos\n",
    "    for suffix in [\".parquet.gzip\", \".fth\", \".xlsx\"]:\n",
    "        if not (stel := pasta / f\"stel{suffix}\").is_file():\n",
    "            raise FileNotFoundError(f\"Arquivo {stel} n√£o encontrado\")\n",
    "        if not (radcom := pasta / f\"radcom{suffix}\").is_file():\n",
    "            raise FileNotFoundError(f\"Arquivo {radcom} n√£o encontrado\")\n",
    "        if not (mosaico := pasta / f\"mosaico{suffix}\").is_file():\n",
    "            raise FileNotFoundError(f\"Arquivo {mosaico} n√£o encontrado\")\n",
    "        break\n",
    "    if not (icao := pasta / \"icao.xlsx\").is_file():  # ICAO\n",
    "        raise FileNotFoundError(f\"Arquivo {icao} n√£o encontrado\")\n",
    "    if not (pmec := pasta / \"aisw.xlsx\").is_file():  # PMEC\n",
    "        raise FileNotFoundError(f\"Arquivo {pmec} n√£o encontrado\")\n",
    "    if not (geo := pasta / \"aisg.xlsx\").is_file():  # GEO\n",
    "        raise FileNotFoundError(f\"Arquivo {geo} n√£o encontrado\")\n",
    "    # Modifica√ß√£o\n",
    "    mod_stel = datetime.fromtimestamp(stel.stat().st_mtime).strftime(\n",
    "        \"%d/%m/%Y %H:%M:%S\"\n",
    "    )\n",
    "    mod_radcom = datetime.fromtimestamp(radcom.stat().st_mtime).strftime(\n",
    "        \"%d/%m/%Y %H:%M:%S\"\n",
    "    )\n",
    "    mod_mosaico = datetime.fromtimestamp(mosaico.stat().st_mtime).strftime(\n",
    "        \"%d/%m/%Y %H:%M:%S\"\n",
    "    )\n",
    "    mod_icao = pd.read_excel(icao, engine=\"openpyxl\", sheet_name=\"ExtractDate\").columns[\n",
    "        0\n",
    "    ]\n",
    "    mod_aisw = pd.read_excel(pmec, engine=\"openpyxl\", sheet_name=\"ExtractDate\").columns[\n",
    "        0\n",
    "    ]\n",
    "    mod_aisg = pd.read_excel(geo, engine=\"openpyxl\", sheet_name=\"ExtractDate\").columns[\n",
    "        0\n",
    "    ]\n",
    "    return {\n",
    "        \"STEL\": mod_stel,\n",
    "        \"SRD\": mod_radcom,\n",
    "        \"MOSAICO\": mod_mosaico,\n",
    "        \"ICAO\": mod_icao,\n",
    "        \"AISW\": mod_aisw,\n",
    "        \"AISG\": mod_aisg,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2af3f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_db(\n",
    "    path: Union[str, Path],  # Pasta onde salvar os arquivos\",\n",
    "    connSQL: pyodbc.Connection = None,  # Objeto de conex√£o do banco SQL Server\n",
    "    clientMongoDB: MongoClient = None,  # Objeto de conex√£o do banco MongoDB\n",
    ") -> pd.DataFrame:  # Retorna o DataFrame com as bases da Anatel e da Aeron√°utica\n",
    "    \"\"\"L√™ e opcionalmente atualiza as bases da Anatel, mescla as bases da Aeron√°utica, salva e retorna o arquivo\n",
    "    A atualiza√ß√£o junto √†s bases de dados da Anatel √© efetuada caso ambos objetos de banco `connSQL` e `clientMongoDB` forem v√°lidos`\n",
    "    \"\"\"\n",
    "    dest = Path(path)\n",
    "    dest.mkdir(parents=True, exist_ok=True)\n",
    "    print(\":scroll:[green]Lendo as bases de dados da Anatel...\")\n",
    "    # if not all([connSQL, clientMongoDB]):\n",
    "    #     raise ConnectionError(f\"Verifique os conectores de banco de dados: {connSQL} e {clientMongoDB}\")\n",
    "    rd = read_base(path, connSQL, clientMongoDB)\n",
    "    rd[\"#Esta√ß√£o\"] = rd[\"N√∫mero_Esta√ß√£o\"]\n",
    "    rd.loc[rd.Multiplicidade != \"1\", \"#Esta√ß√£o\"] = (\n",
    "        rd.loc[rd.Multiplicidade != \"1\", \"N√∫mero_Esta√ß√£o\"]\n",
    "        + \"+\"\n",
    "        + rd.loc[rd.Multiplicidade != \"1\", \"Multiplicidade\"]\n",
    "    )\n",
    "    rd[\"Descri√ß√£o\"] = (\n",
    "        \"[\"\n",
    "        + rd.Fonte.fillna(\"NI\")\n",
    "        + \"] \"\n",
    "        + rd.Status.fillna(\"NI\")\n",
    "        + \", \"\n",
    "        + rd.Classe.fillna(\"NI\")\n",
    "        + \", \"\n",
    "        + rd.Entidade.fillna(\"NI\").str.title()\n",
    "        + \" (\"\n",
    "        + rd.Fistel.fillna(\"NI\")\n",
    "        + \", \"\n",
    "        + rd[\"#Esta√ß√£o\"].fillna(\"NI\")\n",
    "        + \"), \"\n",
    "        + rd.Munic√≠pio.fillna(\"NI\")\n",
    "        + \"/\"\n",
    "        + rd.UF.fillna(\"NI\")\n",
    "    )\n",
    "\n",
    "    rd.loc[rd.Coords_Valida == \"0\", \"Descri√ß√£o\"] = (\n",
    "        rd.loc[rd.Coords_Valida == \"0\", \"Descri√ß√£o\"] + \"*\"\n",
    "    )\n",
    "\n",
    "    export_columns = [\n",
    "        \"Frequ√™ncia\",\n",
    "        \"Latitude\",\n",
    "        \"Longitude\",\n",
    "        \"Descri√ß√£o\",\n",
    "        \"Num_Servi√ßo\",\n",
    "        \"N√∫mero_Esta√ß√£o\",\n",
    "        \"Classe_Emiss√£o\",\n",
    "        \"Largura_Emiss√£o(kHz)\",\n",
    "    ]\n",
    "    rd = rd.loc[:, export_columns]\n",
    "    rd.columns = APP_ANALISE\n",
    "    print(\":airplane:[blue]Adicionando os registros da Aeron√°utica.\")\n",
    "    aero = read_aero(path, update=False)\n",
    "    rd = merge_close_rows(rd, aero)\n",
    "    print(\":card_file_box:[green]Salvando os arquivos...\")\n",
    "    versiondb = json.loads((dest.parent / \"VersionFile.json\").read_text())\n",
    "    mod_times = get_modtimes(path)\n",
    "    mod_times[\"ReleaseDate\"] = datetime.today().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    for c in [\"Latitude\", \"Longitude\"]:\n",
    "        rd.loc[:, c] = rd.loc[:, c].fillna(-1).astype(\"float32\")\n",
    "    rd[\"Frequency\"] = rd[\"Frequency\"].astype(\"float64\")\n",
    "    rd[\"Description\"] = rd[\"Description\"].astype(\"string\").fillna(\"NI\")\n",
    "    rd[\"Service\"] = rd.Service.fillna(\"-1\").astype(\"int32\")\n",
    "    rd[\"Station\"] = rd.Station.fillna(\"-1\").astype(\"int16\")\n",
    "    rd.loc[rd.Station == \"\", \"Station\"] = -1\n",
    "    rd.loc[rd.BW == \"\", \"BW\"] = \"-1\"\n",
    "    rd[\"BW\"] = rd[\"BW\"].astype(\"float32\").fillna(-1)\n",
    "    rd[\"Class\"] = rd.Class.fillna(\"NI\").astype(\"category\")\n",
    "    rd = (\n",
    "        rd.drop_duplicates(keep=\"first\")\n",
    "        .sort_values(by=[\"Frequency\", \"Latitude\", \"Longitude\"])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    rd[\"Id\"] = [f\"#{i+1}\" for i in rd.index]\n",
    "    rd[\"Id\"] = rd.Id.astype(\"string\")\n",
    "    rd = rd.loc[\n",
    "        :,\n",
    "        [\n",
    "            \"Id\",\n",
    "            \"Frequency\",\n",
    "            \"Latitude\",\n",
    "            \"Longitude\",\n",
    "            \"Description\",\n",
    "            \"Service\",\n",
    "            \"Station\",\n",
    "            \"Class\",\n",
    "            \"BW\",\n",
    "        ],\n",
    "    ]\n",
    "    rd.to_parquet(f\"{dest}/AnatelDB.parquet.gzip\", compression=\"gzip\", index=False)\n",
    "    versiondb[\"anateldb\"][\"Version\"] = bump_version(versiondb[\"anateldb\"][\"Version\"])\n",
    "    versiondb[\"anateldb\"].update(mod_times)\n",
    "    json.dump(versiondb, (dest.parent / \"VersionFile.json\").open(\"w\"))\n",
    "    print(\"Sucesso :zap:\")\n",
    "    return rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40a510fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from extracao.updates import connect_db\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "feb70a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "folder = Path.cwd().parent / 'dados'\n",
    "# conn = connect_db()\n",
    "# uri = os.environ['MONGO_URI']\n",
    "# mongo_client = MongoClient(uri)\n",
    "# mongo_client.server_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac178478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">üìú<span style=\"color: #008000; text-decoration-color: #008000\">Lendo as bases de dados da Anatel...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "üìú\u001b[32mLendo as bases de dados da Anatel\u001b[0m\u001b[32m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚úà<span style=\"color: #000080; text-decoration-color: #000080\">Adicionando os registros da Aeron√°utica.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚úà\u001b[34mAdicionando os registros da Aeron√°utica.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfda63342bc6439793397c6de19a7a5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/830197 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#|eval: false\n",
    "from pandas_profiling import ProfileReport\n",
    "base = get_db(folder)\n",
    "base = pd.read_parquet(f\"{Path.cwd().parent}/dados/AnatelDB.parquet.gzip\")\n",
    "base['Frequency'] = base['Frequency'].astype('category')\n",
    "profile = ProfileReport(base, config_file='report_config.yaml')\n",
    "profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8a9d91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('db')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "bc0c9c419a5a59e8a5d5bf28d023951ba56e2f8744a354d21e9b69280dbe5840"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

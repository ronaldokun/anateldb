{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp query\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queries\n",
    "\n",
    "> Este m√≥dulo executa as queries sql / MongoDB necess√°rias para baixar os dados do STEL, RADCOM e MOSAICO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import requests\n",
    "from decimal import *\n",
    "from typing import *\n",
    "from gazpacho import Soup\n",
    "from rich.progress import track\n",
    "from pathlib import Path\n",
    "from unidecode import unidecode\n",
    "import pandas as pd\n",
    "import pandas_read_xml as pdx\n",
    "import pyodbc\n",
    "import re\n",
    "import xml.etree.ElementTree as et\n",
    "from zipfile import ZipFile\n",
    "import collections\n",
    "from fastcore.utils import listify\n",
    "from fastcore.foundation import L\n",
    "from anateldb.constants import console\n",
    "getcontext().prec = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "TIMEOUT = 5\n",
    "RELATORIO = \"http://sistemas.anatel.gov.br/se/eApp/reports/b/srd/resumo_sistema.php?id={id}&state={state}\"\n",
    "ESTACOES = \"http://sistemas.anatel.gov.br/se/public/file/b/srd/estacao_rd.zip\"\n",
    "ESTACAO = \"http://sistemas.anatel.gov.br/se/public/view/b/srd.php?wfid=estacoes&id={}\"\n",
    "PLANO_BASICO = \"http://sistemas.anatel.gov.br/se/public/file/b/srd/Canais.zip\"\n",
    "HISTORICO = (\n",
    "    \"http://sistemas.anatel.gov.br/se/public/file/b/srd/documento_historicos.zip\"\n",
    ")\n",
    "REJECT_ESTACOES = [\n",
    "    \"atenuacao\",\n",
    "    \"historico_documentos\",\n",
    "    \"estacao_auxiliar\",\n",
    "    \"rds\",\n",
    "    \"aprovacao_locais\",\n",
    "    \"item\",\n",
    "]\n",
    "COL_ESTACOES = (\n",
    "    \"siglaservico\",\n",
    "    \"num_servico\",\n",
    "    \"state\",\n",
    "    \"entidade\",\n",
    "    \"fistel\",\n",
    "    \"municipio\",\n",
    "    \"uf\",\n",
    "    \"id\",\n",
    "    \"numero_estacao\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "    \"cnpj\",\n",
    "    \"habilitacao_datavalfreq\",\n",
    ")\n",
    "NEW_ESTACOES = [\n",
    "    \"Servi√ßo\",\n",
    "    \"Num_Servi√ßo\",\n",
    "    \"Status\",\n",
    "    \"Entidade\",\n",
    "    \"Fistel\",\n",
    "    \"Munic√≠pio\",\n",
    "    \"UF\",\n",
    "    \"Id\",\n",
    "    \"N√∫mero_da_Esta√ß√£o\",\n",
    "    \"Latitude_Transmissor\",\n",
    "    \"Longitude_Transmissor\",\n",
    "    \"CNPJ\",\n",
    "    \"Validade_RF\",\n",
    "    \"Num_Ato\",\n",
    "    \"Data_Ato\",\n",
    "]\n",
    "COL_PB = (\n",
    "    \"id\",\n",
    "    \"municipio\",\n",
    "    \"frequencia\",\n",
    "    \"classe\",\n",
    "    \"servico\",\n",
    "    \"entidade\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "    \"uf\",\n",
    "    \"status\",\n",
    "    \"cnpj\",\n",
    "    \"fistel\",\n",
    "    'canal'\n",
    ")\n",
    "NEW_PB = (\n",
    "    \"Id\",\n",
    "    \"Munic√≠pio\",\n",
    "    \"Frequ√™ncia\",\n",
    "    \"Classe\",\n",
    "    \"Servi√ßo\",\n",
    "    \"Entidade\",\n",
    "    \"Latitude_Esta√ß√£o\",\n",
    "    \"Longitude_Esta√ß√£o\",\n",
    "    \"UF\",\n",
    "    \"Status\",\n",
    "    \"CNPJ\",\n",
    "    \"Fistel\",\n",
    "    \"Canal\"\n",
    ")\n",
    "TELECOM = (\n",
    "    \"Frequ√™ncia\",\n",
    "    \"Servi√ßo\",\n",
    "    \"Entidade\",\n",
    "    \"Fistel\",\n",
    "    \"N√∫mero da Esta√ß√£o\",\n",
    "    \"Munic√≠pio\",\n",
    "    \"UF\",\n",
    "    \"Latitude\",\n",
    "    \"Longitude\",\n",
    ")\n",
    "RADIODIFUSAO = (\n",
    "    \"Frequ√™ncia\",\n",
    "    \"Num_Servi√ßo\",\n",
    "    \"Status\",\n",
    "    \"Classe\",\n",
    "    \"Entidade\",\n",
    "    \"Fistel\",\n",
    "    \"N√∫mero_da_Esta√ß√£o\",\n",
    "    \"Munic√≠pio\",\n",
    "    \"UF\",\n",
    "    \"Latitude\",\n",
    "    \"Longitude\",\n",
    "    \"Validade_RF\",\n",
    "    \"Num_Ato\",\n",
    "    \"Data_Ato\",\n",
    ")\n",
    "\n",
    "APP_ANALISE = (\n",
    "    \"Frequency\",\n",
    "    \"Latitude\",\n",
    "    \"Longitude\",\n",
    "    \"Description\",\n",
    "    \"Service\",\n",
    "    \"Station\",\n",
    "    \"ActNumber\",\n",
    "    \"ActDate\",\n",
    "    \"ValRF\",\n",
    ")\n",
    "\n",
    "ENTIDADES = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "RADCOM = \"\"\"\n",
    "       select f.MedFrequenciaInicial as 'Frequ√™ncia',\n",
    "       Sitarweb.dbo.FN_SRD_RetornaIndFase(PB.NumServico, Pr.idtPedidoRadcom) as 'Fase',\n",
    "       Sitarweb.dbo.FN_SRD_RetornaSiglaSituacao(h.IdtHabilitacao, Es.IdtEstacao) as 'Situa√ß√£o',\n",
    "       uf.SiglaUnidadeFrequencia as 'Unidade',\n",
    "       e.NomeEntidade as 'Entidade',\n",
    "       h.NumFistel as 'Fistel',\n",
    "       es.NumEstacao as 'N√∫mero da Esta√ß√£o',\n",
    "       m.NomeMunicipio as 'Munic√≠pio',\n",
    "       pb.SiglaUF as 'UF',\n",
    "       es.MedLatitudeDecimal as 'Latitude',\n",
    "       es.MedLongitudeDecimal as 'Longitude',\n",
    "       e.NumCnpjCpf as 'CNPJ'\n",
    "from ENTIDADE e\n",
    "inner join HABILITACAO h on h.IdtEntidade = e.IdtEntidade\n",
    "inner join SRD_PEDIDORADCOM pr on pr.IdtHabilitacao = h.IdtHabilitacao\n",
    "inner join SRD_PLANOBASICO pb on pb.IdtPlanoBasico = pr.IdtPlanoBasico\n",
    "inner join estacao es on es.IdtHabilitacao = h.IdtHabilitacao\n",
    "inner join FREQUENCIA f on f.IdtEstacao = es.IdtEstacao\n",
    "inner join UnidadeFrequencia uf on uf.IdtUnidadeFrequencia = f.IdtUnidadeFrequencia\n",
    "inner join Municipio m on m.CodMunicipio = pb.CodMunicipio\n",
    "where h.NumServico = '231'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "STEL = \"\"\"IF OBJECT_ID('tempDB..##faixas','U') is not null\n",
    "drop table ##faixas\n",
    "create table ##faixas (id int not null, faixa varchar(20), inic float, fim float,);\n",
    "insert into ##faixas values(0,'De 20 MHz - 6 GHz','20000', '6000000');\n",
    "\n",
    "select distinct f.MedTransmissaoInicial as 'Frequ√™ncia',\n",
    "uf.SiglaUnidadeFrequencia as 'Unidade',\n",
    "e.NumServico as 'Servi√ßo',\n",
    "ent.NomeEntidade as 'Entidade',\n",
    "h.NumFistel as 'Fistel',\n",
    "e.NumEstacao as 'N√∫mero da Esta√ß√£o',\n",
    "mu.NomeMunicipio as 'Munic√≠pio',\n",
    "e.SiglaUf as 'UF',\n",
    "e.MedLatitudeDecimal as 'Latitude',\n",
    "e.MedLongitudeDecimal as 'Longitude',\n",
    "ent.NumCnpjCpf as 'CNPJ',\n",
    "c.DataValidadeRadiofrequencia as 'Validade_RF'\n",
    "from contrato c\n",
    "inner join estacao e on e.IdtContrato = c.Idtcontrato\n",
    "inner join frequencia f on f.IdtEstacao = e.IdtEstacao\n",
    "inner join HABILITACAO h on h.IdtHabilitacao = c.IdtHabilitacao\n",
    "inner join entidade ent on ent.IdtEntidade = h.IdtEntidade\n",
    "inner join endereco en on en.IdtEstacao = e.IdtEstacao\n",
    "inner join Municipio mu on mu.CodMunicipio = en.CodMunicipio\n",
    "inner join Servico s on s.NumServico = h.NumServico and s.IdtServicoAreaAtendimento = 4\n",
    "left join UnidadeFrequencia uf on uf.IdtUnidadeFrequencia = f.IdtUnidadeTransmissao\n",
    "left outer join ##faixas fx on (\n",
    "(fx.inic <= f.MedRecepcaoInicialKHz and fx.fim >= f.MedRecepcaoInicialKHz)\n",
    "or (fx.inic <= f.MedTransmissaoInicialKHz and fx.fim >= f.medtransmissaoinicialkhz)\n",
    "or (fx.inic <= f.MedFrequenciaInicialKHz and fx.fim >= f.MedFrequenciaInicialKHz)\n",
    "or (fx.inic <= f.MedFrequenciaFinalKHz and fx.fim >= f.MedFrequenciaFinalKHz)\n",
    ")\n",
    "where e.DataExclusao is null and\n",
    "fx.faixa is not null and\n",
    "f.MedTransmissaoInicial is not null\n",
    "and h.NumServico <> '010'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otimiza√ß√£o dos Tipos de dados\n",
    "A serem criados dataframes, normalmente a tipo de data √© aquele com maior resolu√ß√£o poss√≠vel, nem sempre isso √© necess√°rio, os arquivos de espectro mesmo possuem somente uma casa decimal, portanto um `float16` j√° √© suficiente para armazen√°-los. As fun√ß√µes a seguir fazem essa otimiza√ß√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below borrowed from https://medium.com/bigdatarepublic/advanced-pandas-optimize-speed-and-memory-a654b53be6c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def optimize_floats(df: pd.DataFrame, exclude = None) -> pd.DataFrame:\n",
    "    floats = df.select_dtypes(include=[\"float64\"]).columns.tolist()\n",
    "    floats = [c for c in floats if c not in listify(exclude)]\n",
    "    df[floats] = df[floats].apply(pd.to_numeric, downcast=\"float\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def optimize_ints(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ints = df.select_dtypes(include=[\"int64\"]).columns.tolist()\n",
    "    df[ints] = df[ints].apply(pd.to_numeric, downcast=\"integer\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def optimize_objects(df: pd.DataFrame, datetime_features: List[str]) -> pd.DataFrame:\n",
    "    for col in df.select_dtypes(include=[\"object\"]):\n",
    "        if col not in datetime_features:\n",
    "            num_unique_values = len(df[col].unique())\n",
    "            num_total_values = len(df[col])\n",
    "            if float(num_unique_values) / num_total_values < 0.5:\n",
    "                df[col] = df[col].astype(\"category\")\n",
    "        else:\n",
    "            df[col] = pd.to_datetime(df[col]).dt.date\n",
    "    return df\n",
    "\n",
    "\n",
    "def df_optimize(df: pd.DataFrame, datetime_features: List[str] = [], exclude = None):\n",
    "    return optimize_floats(optimize_ints(optimize_objects(df, datetime_features)), exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def connect_db():\n",
    "    \"\"\"Conecta ao Banco ANATELBDRO01 e retorna o 'cursor' (iterador) do Banco pronto para fazer itera√ß√µes\"\"\"\n",
    "    conn = pyodbc.connect(\n",
    "        \"Driver={ODBC Driver 17 for SQL Server};\"\n",
    "        \"Server=ANATELBDRO01;\"\n",
    "        \"Database=SITARWEB;\"\n",
    "        \"Trusted_Connection=yes;\"\n",
    "        \"MultipleActiveResultSets=True;\",\n",
    "        timeout=TIMEOUT,\n",
    "    )\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow\n",
    "def test_connection():\n",
    "    conn = connect_db()\n",
    "    cursor = conn.cursor()\n",
    "    for query in (RADCOM, STEL):\n",
    "        cursor.execute(query)\n",
    "        test_eq(type(cursor.fetchone()), pyodbc.Row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def row2dict(row):\n",
    "    \"\"\"Receives a json row and return the dictionary from it\"\"\"\n",
    "    return {k: v for k, v in row.items()}\n",
    "\n",
    "\n",
    "def dict2cols(df, reject=()):\n",
    "    \"\"\"Recebe um dataframe com dicion√°rios nas c√©lulas e extrai os dicion√°rios como colunas\n",
    "    Opcionalmente ignora e exclue as colunas em reject\n",
    "    \"\"\"\n",
    "    for column in df.columns:\n",
    "        if column in reject:\n",
    "            df.drop(column, axis=1, inplace=True)\n",
    "            continue\n",
    "        if type(df[column].iloc[0]) == collections.OrderedDict:\n",
    "            try:\n",
    "                new_df = pd.DataFrame(df[column].apply(row2dict).tolist())\n",
    "                df = pd.concat([df, new_df], axis=1)\n",
    "                df.drop(column, axis=1, inplace=True)\n",
    "            except AttributeError:\n",
    "                continue\n",
    "    return df\n",
    "\n",
    "\n",
    "def parse_plano_basico(row, cols=COL_PB):\n",
    "    \"\"\"Receives a json row and filter the column in `cols`\"\"\"\n",
    "    return {k: row[k] for k in cols}\n",
    "\n",
    "\n",
    "def scrape_dataframe(id_list):\n",
    "    df = pd.DataFrame()\n",
    "    for id_ in track(id_list, description=\"Baixando informa√ß√µes complementares da Web\"):\n",
    "        html = requests.get(ESTACAO.format(id_))\n",
    "        df = df.append(pd.read_html(Soup(html.text).find(\"table\").html)[0])\n",
    "    \n",
    "    df.rename(columns={'NumFistel': 'Fistel',\n",
    "                       'Num Servi√ßo': 'Num_Servi√ßo'}, inplace=True)\n",
    "    return df[[\"Status\", \"Entidade\", \"Fistel\", \"Frequ√™ncia\", \"Classe\", 'Num_Servi√ßo', 'Munic√≠pio', 'UF']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def read_stel(pasta, update=False):\n",
    "    \"\"\"L√™ o banco de dados salvo localmente do STEL. Opcionalmente o atualiza pelo Banco de Dados ANATELBDRO01.\"\"\"\n",
    "    if update:\n",
    "        update_stel(pasta)\n",
    "    if (file := Path(f\"{pasta}/stel.fth\")).exists():\n",
    "        stel = pd.read_feather(file)\n",
    "    elif (file := Path(f\"{pasta}/stel.csv\")).exists():\n",
    "        stel = pd.read_csv(file)\n",
    "    elif (file := Path(f\"{pasta}/Base_de_Dados.xlsx\")).exists():\n",
    "        stel = pd.read_excel(file, sheet_name=\"Stel\", engine=\"openpyxl\")\n",
    "    else:\n",
    "        update_stel(pasta)\n",
    "        try:\n",
    "            stel = pd.read_feather(Path(f\"{pasta}/stel.fth\"))\n",
    "        except FileNotFoundError as e:\n",
    "            raise ConnectionError(\n",
    "                \"Base de Dados do Stel inexistente e n√£o foi poss√≠vel atualiz√°-la\"\n",
    "            ) from e\n",
    "    return df_optimize(stel)\n",
    "\n",
    "\n",
    "def read_radcom(pasta, update=False):\n",
    "    \"\"\"L√™ o banco de dados salvo localmente de RADCOM. Opcionalmente o atualiza pelo Banco de Dados ANATELBDRO01.\"\"\"\n",
    "    if update:\n",
    "        update_radcom(pasta)\n",
    "    if (file := Path(f\"{pasta}/radcom.fth\")).exists():\n",
    "        radcom = pd.read_feather(file)\n",
    "    elif (file := Path(f\"{pasta}/radcom.csv\")).exists():\n",
    "        radcom = pd.read_csv(file)\n",
    "    elif (file := Path(f\"{pasta}/Base_de_Dados.xlsx\")).exists():\n",
    "        radcom = pd.read_excel(file, sheet_name=\"Radcom\", engine=\"openpyxl\")\n",
    "    else:\n",
    "        update_radcom(pasta)\n",
    "        try:\n",
    "            radcom = pd.read_feather(Path(f\"{pasta}/radcom.fth\"))\n",
    "        except FileNotFoundError as e:\n",
    "            raise ConnectionError(\n",
    "                \"Base de Dados do Stel inexistente e n√£o foi poss√≠vel atualiz√°-la\"\n",
    "            ) from e\n",
    "    return df_optimize(radcom)\n",
    "\n",
    "\n",
    "def read_esta√ß√µes(path):\n",
    "    def extrair_ato(row):\n",
    "        if not isinstance(row, str):\n",
    "            row = listify(row)[::-1]\n",
    "            for d in row:\n",
    "                if not isinstance(d, dict):\n",
    "                    continue\n",
    "                if (d.get(\"@TipoDocumento\") == \"Ato\") and (\n",
    "                    d.get(\"@Razao\") == \"Autoriza o Uso de Radiofrequ√™ncia\"\n",
    "                ):\n",
    "                    return d[\"@NumDocumento\"], d[\"@DataDOU\"][:10]\n",
    "            else:\n",
    "                return \"\", \"\"\n",
    "        return \"\", \"\"\n",
    "\n",
    "    es = pdx.read_xml(path, [\"estacao_rd\"])\n",
    "    dfs = []\n",
    "    for i in range(es.shape[0]):\n",
    "        df = pd.DataFrame(es[\"row\"][i]).replace(\"\", pd.NA)\n",
    "        df = dict2cols(df)\n",
    "        df.columns = [unidecode(c).lower().replace(\"@\", \"\") for c in df.columns]\n",
    "        dfs.append(df)\n",
    "    df = pd.concat(dfs)\n",
    "    df = df[df.state.str.contains(\"-C1$|-C2$|-C3$|-C4$|-C7|-C98$\")].reset_index(drop=True)\n",
    "    docs = L(df.historico_documentos.apply(extrair_ato).tolist())\n",
    "    df = df.loc[:, COL_ESTACOES]\n",
    "    df[\"Num_Ato\"] = docs.itemgot(0).map(str)\n",
    "    df[\"Data_Ato\"] = docs.itemgot(1).map(str)\n",
    "    df.columns = NEW_ESTACOES\n",
    "    df['Entidade'] = df.Entidade.fillna('')\n",
    "    ENTIDADES.update({r.Fistel : r.Entidade for r in df.itertuples() if r.Entidade != ''})\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_plano_basico(path):\n",
    "    pb = pdx.read_xml(path, [\"plano_basico\"])\n",
    "    # df = pd.DataFrame(df[\"row\"].apply(row2dict).tolist()).replace(\"\", pd.NA)\n",
    "    dfs = []\n",
    "    for i in range(pb.shape[0]):\n",
    "        df = pd.DataFrame(pb[\"row\"][i]).replace(\"\", pd.NA)\n",
    "        df = dict2cols(df)\n",
    "        df.columns = [unidecode(c).lower().replace(\"@\", \"\") for c in df.columns]\n",
    "        dfs.append(df)\n",
    "    df = pd.concat(dfs)\n",
    "    df = df.loc[df.pais == \"BRA\", COL_PB].reset_index(drop=True)\n",
    "    df.columns = NEW_PB\n",
    "    df.sort_values([\"Id\", \"Canal\"], inplace=True)\n",
    "    df['Entidade'] = df.Entidade.fillna('')\n",
    "    ENTIDADES.update({r.Fistel : r.Entidade for r in df.itertuples() if r.Entidade != ''})\n",
    "    df = df.groupby(\"Id\", as_index=False).first()  # remove duplicated with NaNs\n",
    "    df.dropna(subset=['Status'], inplace=True)\n",
    "    df = df[df.Status.str.contains(\"-C1$|-C2$|-C3$|-C4$|-C7|-C98$\")].reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def read_historico(path):\n",
    "    regex = r\"\\s([a-zA-Z]+)=\\'{1}([\\w\\-\\ :\\.]*)\\'{1}\"\n",
    "    with ZipFile(path) as xmlzip:\n",
    "        with xmlzip.open(\"documento_historicos.xml\", \"r\") as xml:\n",
    "            xml_list = xml.read().decode().split(\"\\n\")[2:-1]\n",
    "    dict_list = []\n",
    "    for item in xml_list:\n",
    "        matches = re.finditer(regex, item, re.MULTILINE)\n",
    "        dict_list.append(dict(match.groups() for match in matches))\n",
    "    df = pd.DataFrame(dict_list)\n",
    "    df = df[\n",
    "        (df.tipoDocumento == \"Ato\") & (df.razao == \"Autoriza o Uso de Radiofrequ√™ncia\")\n",
    "    ].reset_index()\n",
    "    df = df.loc[:, [\"id\", \"numeroDocumento\", \"orgao\", \"dataDocumento\"]]\n",
    "    df.columns = [\"Id\", \"Num_Ato\", \"√ìrgao\", \"Data_Ato\"]\n",
    "    df[\"Data_Ato\"] = pd.to_datetime(df.Data_Ato)\n",
    "    return df.sort_values(\"Data_Ato\").groupby(\"Id\").last().reset_index()\n",
    "\n",
    "\n",
    "def read_mosaico(pasta, update=False):\n",
    "    if update:\n",
    "        update_mosaico(pasta)\n",
    "    if not (file := Path(f\"{pasta}/mosaico.xlsx\")).exists():\n",
    "        return read_mosaico(pasta, update=True)\n",
    "    return pd.read_excel(f\"{pasta}/mosaico.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def clean_merge(pasta, df):\n",
    "    df = df.copy()\n",
    "    COLS = [c for c in df.columns if \"_x\" in c]\n",
    "    for col in COLS:\n",
    "        col_x = col\n",
    "        col_y = col.split(\"_\")[0] + \"_y\"\n",
    "        if df[col_x].count() > df[col_y].count():\n",
    "            a, b = col_x, col_y\n",
    "        else:\n",
    "            a, b = col_y, col_x\n",
    "\n",
    "        df.loc[df[a].isna(), a] = df.loc[df[a].isna(), b]\n",
    "        df.drop(b, axis=1, inplace=True)\n",
    "        df.rename({a: a[:-2]}, axis=1, inplace=True)\n",
    "\n",
    "    df.loc[df.Latitude_Transmissor == \"\", \"Latitude_Transmissor\"] = df.loc[\n",
    "        df.Latitude_Transmissor == \"\", \"Latitude_Esta√ß√£o\"\n",
    "    ]\n",
    "    df.loc[df.Longitude_Transmissor == \"\", \"Longitude_Transmissor\"] = df.loc[\n",
    "        df.Longitude_Transmissor == \"\", \"Longitude_Esta√ß√£o\"\n",
    "    ]\n",
    "    df.loc[df.Latitude_Transmissor.isna(), \"Latitude_Transmissor\"] = df.loc[\n",
    "        df.Latitude_Transmissor.isna(), \"Latitude_Esta√ß√£o\"\n",
    "    ]\n",
    "    df.loc[df.Longitude_Transmissor.isna(), \"Longitude_Transmissor\"] = df.loc[\n",
    "        df.Longitude_Transmissor.isna(), \"Longitude_Esta√ß√£o\"\n",
    "    ]\n",
    "    df.drop([\"Latitude_Esta√ß√£o\", \"Longitude_Esta√ß√£o\"], axis=1, inplace=True)\n",
    "    df.rename(\n",
    "        columns={\n",
    "            \"Latitude_Transmissor\": \"Latitude\",\n",
    "            \"Longitude_Transmissor\": \"Longitude\",\n",
    "        },\n",
    "        inplace=True,\n",
    "    )\n",
    "    m = pd.read_excel(f\"{pasta}/munic√≠pios.xlsx\", engine='openpyxl')\n",
    "    m.loc[\n",
    "        m.Munic√≠pio == \"Sant'Ana do Livramento\", \"Munic√≠pio\"\n",
    "    ] = \"Santana do Livramento\"\n",
    "    m[\"Munic√≠pio\"] = (\n",
    "        m.Munic√≠pio.apply(unidecode).str.lower().str.replace(\"'\", \" \")\n",
    "    )  # (lambda x: \"\".join(e for e in x if e.isalnum()))\n",
    "    m[\"UF\"] = m.UF.str.lower()\n",
    "    df[\"Coordenadas_do_Munic√≠pio\"] = False\n",
    "    df[\"Latitude\"] = df.Latitude.str.replace(\",\", \".\")\n",
    "    df[\"Longitude\"] = df.Longitude.str.replace(\",\", \".\")\n",
    "    df[\"Frequ√™ncia\"] = df.Frequ√™ncia.str.replace(\",\", \".\")\n",
    "    df.loc[df[\"Munic√≠pio\"] == \"Poxor√©o\", \"Munic√≠pio\"] = \"Poxor√©u\"\n",
    "    df.loc[df[\"Munic√≠pio\"] == \"Couto de Magalh√£es\", \"Munic√≠pio\"] = \"Couto Magalh√£es\"\n",
    "    for row in df[(df.Latitude == \"\") | (df.Latitude.isna())].itertuples():\n",
    "        try:\n",
    "            left = unidecode(row.Munic√≠pio).lower()\n",
    "            m_coord = (\n",
    "                m.loc[\n",
    "                    (m.Munic√≠pio == left) & (m.UF == row.UF.lower()),\n",
    "                    [\"Latitude\", \"Longitude\"],\n",
    "                ]\n",
    "                .values.flatten()\n",
    "                .tolist()\n",
    "            )\n",
    "            df.loc[row.Index, \"Latitude\"] = m_coord[0]\n",
    "            df.loc[row.Index, \"Longitude\"] = m_coord[1]\n",
    "            df.loc[row.Index, \"Coordenadas_do_Munic√≠pio\"] = True\n",
    "        except ValueError:\n",
    "            print(left, row.UF, m_coord)\n",
    "            continue\n",
    "\n",
    "    freq_nans = df[df.Frequ√™ncia.isna()].Id.tolist()\n",
    "    complement_df = scrape_dataframe(freq_nans)\n",
    "    df.loc[\n",
    "        df.Frequ√™ncia.isna(), [\"Status\", \"Entidade\", \"Fistel\", \"Frequ√™ncia\", \"Classe\", \n",
    "                               'Num_Servi√ßo', 'Munic√≠pio', 'UF']\n",
    "        ] = complement_df.values\n",
    "        \n",
    "    for r in df[(df.Entidade.isna()) | (df.Entidade == '')].itertuples():\n",
    "        df.loc[r.Index, 'Entidade'] = ENTIDADES.get(r.Fistel, '')\n",
    "        \n",
    "    \n",
    "     \n",
    "    df.loc[df[\"N√∫mero_da_Esta√ß√£o\"] == \"\", \"N√∫mero_da_Esta√ß√£o\"] = -1\n",
    "#     df[\"N√∫mero_da_Esta√ß√£o\"] = df[\"N√∫mero_da_Esta√ß√£o\"].astype(\"int\")\n",
    "#     df[\"Canal\"] = df[\"Canal\"].astype(\"str\")\n",
    "#     df.loc[(df.Classe == '') | (df.Classe.isna()), 'Classe'] = 'Z'\n",
    "#     df = df_optimize(df, [\"Validade_RF\", \"Data_Ato\"])\n",
    "#     df['Num_Servi√ßo'] = df.Num_Servi√ßo.astype('category')\n",
    "#     df['Fistel'] = df.Fistel.astype('category')\n",
    "#     df.loc[df['Validade_RF'].notna(), 'Validade_RF'] = df.loc[df['Validade_RF'].notna(), 'Validade_RF'].astype(str).str.slice(0,10)\n",
    "#     df.loc[df['Data_Ato'].notna(), 'Data_Ato']  = df.loc[df['Data_Ato'].notna(), 'Data_Ato'].astype(str).str.slice(0,10)\n",
    "    df[\"Latitude\"] = df[\"Latitude\"].astype(\"float\")\n",
    "    df[\"Longitude\"] = df[\"Longitude\"].astype(\"float\")\n",
    "    df[\"Frequ√™ncia\"] = df.Frequ√™ncia.astype(\"float\")\n",
    "    df.loc[df.Servi√ßo == 'OM', 'Frequ√™ncia'] = df.loc[df.Servi√ßo == 'OM', 'Frequ√™ncia'].apply(lambda x: Decimal(x) / Decimal(1000))\n",
    "    df[\"Frequ√™ncia\"] = df.Frequ√™ncia.astype(\"float\")\n",
    "    return df_optimize(df, exclude=['Latitude', 'Longitude', 'Frequ√™ncia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def update_radcom(folder):\n",
    "    \"\"\"Update the Radcom File querying the Database\"\"\"\n",
    "    with console.status(\n",
    "        \"[cyan]Lendo o Banco de Dados de Radcom...\", spinner=\"earth\"\n",
    "    ) as status:\n",
    "        try:\n",
    "            conn = connect_db()\n",
    "            df = pd.read_sql_query(RADCOM, conn)\n",
    "            df = df_optimize(df)\n",
    "            df.to_feather(f\"{folder}/radcom.fth\")\n",
    "        except pyodbc.OperationalError:\n",
    "            status.console.log(\n",
    "                \"N√£o foi poss√≠vel abrir uma conex√£o com o SQL Server. Esta conex√£o somente funciona da rede cabeada!\"\n",
    "            )\n",
    "\n",
    "\n",
    "def update_stel(folder):\n",
    "    \"\"\"Update the Stel File querying the Database\"\"\"\n",
    "    with console.status(\n",
    "        \"[magenta]Lendo o Banco de Dados do STEL. Processo Lento, aguarde...\",\n",
    "        spinner=\"moon\",\n",
    "    ) as status:\n",
    "        try:\n",
    "            conn = connect_db()\n",
    "            df = pd.read_sql_query(STEL, conn)\n",
    "            df = df_optimize(df)\n",
    "            df.to_feather(f\"{folder}/stel.fth\")\n",
    "        except pyodbc.OperationalError:\n",
    "            status.console.log(\n",
    "                \"N√£o foi poss√≠vel abrir uma conex√£o com o SQL Server. Esta conex√£o somente funciona da rede cabeada!\"\n",
    "            )\n",
    "\n",
    "\n",
    "def update_mosaico(pasta):\n",
    "    \"\"\"Update the Mosaico File by downloading the zipped xml file from the Spectrum E Web page\"\"\"\n",
    "    with console.status(\n",
    "        \"[blue]Baixando as Esta√ß√µes do Mosaico...\", spinner=\"shark\"\n",
    "    ) as status:\n",
    "        file = requests.get(ESTACOES)\n",
    "        with open(f\"{pasta}/esta√ß√µes.zip\", \"wb\") as esta√ß√µes:\n",
    "            esta√ß√µes.write(file.content)\n",
    "    with console.status(\n",
    "        \"[blue]Baixando o Plano B√°sico das Esta√ß√µes...\", spinner=\"weather\"\n",
    "    ) as status:\n",
    "        file = requests.get(PLANO_BASICO)\n",
    "        with open(f\"{pasta}/Canais.zip\", \"wb\") as plano_basico:\n",
    "            plano_basico.write(file.content)\n",
    "    console.print(\"[blue]Consolidando as bases de dados...\")\n",
    "    esta√ß√µes = read_esta√ß√µes(f\"{pasta}/esta√ß√µes.zip\")\n",
    "    plano_basico = read_plano_basico(f\"{pasta}/Canais.zip\")\n",
    "    df = esta√ß√µes.merge(plano_basico, on=\"Id\", how=\"left\")\n",
    "    df = clean_merge(pasta, df)\n",
    "#    df.reset_index(drop=True).to_feather(f\"{pasta}/mosaico.fth\")\n",
    "    with pd.ExcelWriter(f\"{pasta}/mosaico.xlsx\") as workbook:\n",
    "        df.reset_index(drop=True).to_excel(workbook, sheet_name='Sheet1', engine=\"openpyxl\", index=False)\n",
    "    console.print(\"Kb√¥ :vampire:\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">Consolidando as bases de dados...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mConsolidando as bases de dados\u001b[0m\u001b[34m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d3c273bacae44f58547ff0041f049bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Kb√¥ üßõ\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Kb√¥ üßõ\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = update_mosaico(r'D:\\OneDrive - ANATEL\\BaseDados')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()\n",
    "\n",
    "# df.head()\n",
    "\n",
    "# radcom = read_radcom(r'D:\\OneDrive - ANATEL\\BaseDados')\n",
    "\n",
    "# radcom.info()\n",
    "\n",
    "# stel = read_stel(r'D:\\OneDrive - ANATEL\\BaseDados')\n",
    "\n",
    "# stel.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e = read_esta√ß√µes(r'D:\\OneDrive - ANATEL\\BaseDados\\esta√ß√µes.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pb = read_plano_basico(r'D:\\OneDrive - ANATEL\\BaseDados\\Canais.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pb.to_feather(r'D:\\OneDrive - ANATEL\\BaseDados\\plano_basico.fth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = e.merge(pb, on=\"Id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = clean_merge(r'D:\\OneDrive - ANATEL\\BaseDados', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Canal'] = df['Canal'].astype()\n",
    "# df.to_feather(r'D:\\OneDrive - ANATEL\\BaseDados\\mosaico.fth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "\n",
    "# r = requests.get('https://anatel365-my.sharepoint.com/:x:/g/personal/rsilva_anatel_gov_br/ESjSacOqe3xEpodgo9-cRW0ByQD_7fIn_NVpP1A6gz7V0Q?download=1')\n",
    "\n",
    "# r\n",
    "\n",
    "# p = Path(r'D:\\OneDrive - ANATEL\\BaseDados\\AnatelDB.xlsx')\n",
    "\n",
    "# p.write_bytes(r.content)\n",
    "\n",
    "# d = requests.get('https://anatel365-my.sharepoint.com/:x:/g/personal/rsilva_anatel_gov_br/ESjSacOqe3xEpodgo9-cRW0BCaLnzQUHFTH8vdkH7sZwkg?download=1')\n",
    "\n",
    "# p = Path(r'D:\\OneDrive - ANATEL\\BaseDados\\Teste.xlsx')\n",
    "\n",
    "# p.write_bytes(d.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stel = read_stel(r'D:\\OneDrive - ANATEL\\BaseDados')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequ√™ncia</th>\n",
       "      <th>Unidade</th>\n",
       "      <th>Servi√ßo</th>\n",
       "      <th>Entidade</th>\n",
       "      <th>Fistel</th>\n",
       "      <th>N√∫mero da Esta√ß√£o</th>\n",
       "      <th>Munic√≠pio</th>\n",
       "      <th>UF</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>CNPJ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.779999</td>\n",
       "      <td>MHz</td>\n",
       "      <td>078</td>\n",
       "      <td>ASSOCIACAO DOS MOTORISTAS AUTON RADIO TAXI COM...</td>\n",
       "      <td>02031913239</td>\n",
       "      <td>3939987</td>\n",
       "      <td>S√£o Paulo</td>\n",
       "      <td>SP</td>\n",
       "      <td>-23.569084</td>\n",
       "      <td>-46.707279</td>\n",
       "      <td>64019656000139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34.840000</td>\n",
       "      <td>MHz</td>\n",
       "      <td>078</td>\n",
       "      <td>ASSOCIACAO DOS TAXISTAS E RADIO TAXIS MUNIC SA...</td>\n",
       "      <td>02033423808</td>\n",
       "      <td>690190999</td>\n",
       "      <td>S√£o Paulo</td>\n",
       "      <td>SP</td>\n",
       "      <td>-23.474445</td>\n",
       "      <td>-46.656387</td>\n",
       "      <td>67644641000150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.020000</td>\n",
       "      <td>MHz</td>\n",
       "      <td>033</td>\n",
       "      <td>EXPO-TAXI COMUM RADIO LTDA - ME</td>\n",
       "      <td>50010393633</td>\n",
       "      <td>577100645</td>\n",
       "      <td>S√£o Paulo</td>\n",
       "      <td>SP</td>\n",
       "      <td>-23.416111</td>\n",
       "      <td>-46.706944</td>\n",
       "      <td>02107071000113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.439999</td>\n",
       "      <td>MHz</td>\n",
       "      <td>019</td>\n",
       "      <td>INDUSCAL-INDUSTRIA DE CALCARIO LTDA</td>\n",
       "      <td>50000771481</td>\n",
       "      <td>1938380</td>\n",
       "      <td>Riach√£o</td>\n",
       "      <td>MA</td>\n",
       "      <td>-7.520833</td>\n",
       "      <td>-46.141666</td>\n",
       "      <td>05746748000151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38.020000</td>\n",
       "      <td>MHz</td>\n",
       "      <td>019</td>\n",
       "      <td>POLICIA MILITAR</td>\n",
       "      <td>13020046890</td>\n",
       "      <td>1619349</td>\n",
       "      <td>Goi√¢nia</td>\n",
       "      <td>GO</td>\n",
       "      <td>-16.672501</td>\n",
       "      <td>-49.258057</td>\n",
       "      <td>01409671000173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403604</th>\n",
       "      <td>22807.000000</td>\n",
       "      <td>kHz</td>\n",
       "      <td>064</td>\n",
       "      <td>CLARO S.A.</td>\n",
       "      <td>01020422092</td>\n",
       "      <td>895156</td>\n",
       "      <td>Rio de Janeiro</td>\n",
       "      <td>RJ</td>\n",
       "      <td>-22.965000</td>\n",
       "      <td>-43.673332</td>\n",
       "      <td>40432544000147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403605</th>\n",
       "      <td>23113.000000</td>\n",
       "      <td>kHz</td>\n",
       "      <td>019</td>\n",
       "      <td>RAFT TECNOLOGIES BRAZIL SISTEMAS DE TECNOLOGIA...</td>\n",
       "      <td>50411558609</td>\n",
       "      <td>1000352878</td>\n",
       "      <td>Santana de Parna√≠ba</td>\n",
       "      <td>SP</td>\n",
       "      <td>-23.467583</td>\n",
       "      <td>-46.862110</td>\n",
       "      <td>17196674000106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403606</th>\n",
       "      <td>25242.000000</td>\n",
       "      <td>kHz</td>\n",
       "      <td>019</td>\n",
       "      <td>EMBAIXADA DA REPUBLICA TCHECA</td>\n",
       "      <td>50000906590</td>\n",
       "      <td>5050111</td>\n",
       "      <td>Bras√≠lia</td>\n",
       "      <td>DF</td>\n",
       "      <td>-15.819445</td>\n",
       "      <td>-47.880554</td>\n",
       "      <td>00000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403607</th>\n",
       "      <td>26100.500000</td>\n",
       "      <td>kHz</td>\n",
       "      <td>064</td>\n",
       "      <td>CLARO S.A.</td>\n",
       "      <td>01020422092</td>\n",
       "      <td>895180</td>\n",
       "      <td>Recife</td>\n",
       "      <td>PE</td>\n",
       "      <td>-8.051666</td>\n",
       "      <td>-34.929443</td>\n",
       "      <td>40432544000147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403608</th>\n",
       "      <td>26720.000000</td>\n",
       "      <td>kHz</td>\n",
       "      <td>079</td>\n",
       "      <td>TELE TAXI CIDADE LTDA</td>\n",
       "      <td>03020216710</td>\n",
       "      <td>71366</td>\n",
       "      <td>Porto Alegre</td>\n",
       "      <td>RS</td>\n",
       "      <td>-30.063889</td>\n",
       "      <td>-51.200001</td>\n",
       "      <td>90068602000173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>403609 rows √ó 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Frequ√™ncia Unidade Servi√ßo  \\\n",
       "0          34.779999     MHz     078   \n",
       "1          34.840000     MHz     078   \n",
       "2          35.020000     MHz     033   \n",
       "3          36.439999     MHz     019   \n",
       "4          38.020000     MHz     019   \n",
       "...              ...     ...     ...   \n",
       "403604  22807.000000     kHz     064   \n",
       "403605  23113.000000     kHz     019   \n",
       "403606  25242.000000     kHz     019   \n",
       "403607  26100.500000     kHz     064   \n",
       "403608  26720.000000     kHz     079   \n",
       "\n",
       "                                                 Entidade       Fistel  \\\n",
       "0       ASSOCIACAO DOS MOTORISTAS AUTON RADIO TAXI COM...  02031913239   \n",
       "1       ASSOCIACAO DOS TAXISTAS E RADIO TAXIS MUNIC SA...  02033423808   \n",
       "2                        EXPO-TAXI COMUM RADIO LTDA - ME   50010393633   \n",
       "3                     INDUSCAL-INDUSTRIA DE CALCARIO LTDA  50000771481   \n",
       "4                                         POLICIA MILITAR  13020046890   \n",
       "...                                                   ...          ...   \n",
       "403604                                         CLARO S.A.  01020422092   \n",
       "403605  RAFT TECNOLOGIES BRAZIL SISTEMAS DE TECNOLOGIA...  50411558609   \n",
       "403606                      EMBAIXADA DA REPUBLICA TCHECA  50000906590   \n",
       "403607                                         CLARO S.A.  01020422092   \n",
       "403608                              TELE TAXI CIDADE LTDA  03020216710   \n",
       "\n",
       "        N√∫mero da Esta√ß√£o            Munic√≠pio  UF   Latitude  Longitude  \\\n",
       "0                 3939987            S√£o Paulo  SP -23.569084 -46.707279   \n",
       "1               690190999            S√£o Paulo  SP -23.474445 -46.656387   \n",
       "2               577100645            S√£o Paulo  SP -23.416111 -46.706944   \n",
       "3                 1938380              Riach√£o  MA  -7.520833 -46.141666   \n",
       "4                 1619349              Goi√¢nia  GO -16.672501 -49.258057   \n",
       "...                   ...                  ...  ..        ...        ...   \n",
       "403604             895156       Rio de Janeiro  RJ -22.965000 -43.673332   \n",
       "403605         1000352878  Santana de Parna√≠ba  SP -23.467583 -46.862110   \n",
       "403606            5050111             Bras√≠lia  DF -15.819445 -47.880554   \n",
       "403607             895180               Recife  PE  -8.051666 -34.929443   \n",
       "403608              71366         Porto Alegre  RS -30.063889 -51.200001   \n",
       "\n",
       "                  CNPJ  \n",
       "0       64019656000139  \n",
       "1       67644641000150  \n",
       "2       02107071000113  \n",
       "3       05746748000151  \n",
       "4       01409671000173  \n",
       "...                ...  \n",
       "403604  40432544000147  \n",
       "403605  17196674000106  \n",
       "403606  00000000000000  \n",
       "403607  40432544000147  \n",
       "403608  90068602000173  \n",
       "\n",
       "[403609 rows x 11 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "019    344955\n",
       "099     12965\n",
       "604     11508\n",
       "011      9127\n",
       "053      6163\n",
       "125      5600\n",
       "035      4639\n",
       "046      2004\n",
       "507      1987\n",
       "124      1407\n",
       "078      1070\n",
       "017       708\n",
       "079       573\n",
       "033       421\n",
       "064       322\n",
       "108       109\n",
       "012        46\n",
       "132         5\n",
       "Name: Servi√ßo, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stel.Servi√ßo.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COMANDO DA AERONAUTICA                              1112\n",
       "PETROLEO BRASILEIRO S A PETROBRAS                    209\n",
       "EMBRAER S.A.                                         126\n",
       "AZUL LINHAS AEREAS BRASILEIRAS S.A                   123\n",
       "GOL LINHAS AEREAS S.A.                                67\n",
       "                                                    ... \n",
       "EDITORA MODERNA LTDA                                   0\n",
       "EDIVALDO FRANCISCO MENDES                              0\n",
       "EDIVAN ANTONIO ZAVARISI                                0\n",
       "EDIVAN APARECIDO MOYA ARTIOLI                          0\n",
       "√îMEGA SEGURAN√áA E VIGIL√ÇNCIA PATRIMONIAL LTDA ME       0\n",
       "Name: Entidade, Length: 12929, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stel.loc[stel.Servi√ßo == '507', 'Entidade'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anateldb]",
   "language": "python",
   "name": "conda-env-anateldb-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

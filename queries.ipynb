{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp query\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queries\n",
    "\n",
    "> Este m√≥dulo executa as queries sql / MongoDB necess√°rias para baixar os dados do STEL, RADCOM e MOSAICO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import requests\n",
    "from decimal import *\n",
    "from typing import *\n",
    "from gazpacho import Soup\n",
    "from rich.progress import track\n",
    "from pathlib import Path\n",
    "from unidecode import unidecode\n",
    "import pandas as pd\n",
    "import pandas_read_xml as pdx\n",
    "import pyodbc\n",
    "import re\n",
    "import xml.etree.ElementTree as et\n",
    "from zipfile import ZipFile\n",
    "import collections\n",
    "from fastcore.utils import listify\n",
    "from fastcore.foundation import L\n",
    "from fastcore.test import *\n",
    "from anateldb.constants import *\n",
    "from pyarrow import ArrowInvalid\n",
    "getcontext().prec = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otimiza√ß√£o dos Tipos de dados\n",
    "A serem criados dataframes, normalmente a tipo de data √© aquele com maior resolu√ß√£o poss√≠vel, nem sempre isso √© necess√°rio, os arquivos de espectro mesmo possuem somente uma casa decimal, portanto um `float16` j√° √© suficiente para armazen√°-los. As fun√ß√µes a seguir fazem essa otimiza√ß√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below borrowed from https://medium.com/bigdatarepublic/advanced-pandas-optimize-speed-and-memory-a654b53be6c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def optimize_floats(df: pd.DataFrame, exclude = None) -> pd.DataFrame:\n",
    "    floats = df.select_dtypes(include=[\"float64\"]).columns.tolist()\n",
    "    floats = [c for c in floats if c not in listify(exclude)]\n",
    "    df[floats] = df[floats].apply(pd.to_numeric, downcast=\"float\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def optimize_ints(df: pd.DataFrame, exclude=None) -> pd.DataFrame:\n",
    "    ints = df.select_dtypes(include=[\"int64\"]).columns.tolist()\n",
    "    ints = [c for c in ints if c not in listify(exclude)]\n",
    "    df[ints] = df[ints].apply(pd.to_numeric, downcast=\"integer\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def optimize_objects(df: pd.DataFrame, datetime_features: List[str], exclude=None) -> pd.DataFrame:\n",
    "    for col in df.select_dtypes(include=[\"object\"]).columns.tolist():\n",
    "        if col not in datetime_features:\n",
    "            if col in listify(exclude): continue\n",
    "            num_unique_values = len(df[col].unique())\n",
    "            num_total_values = len(df[col])\n",
    "            if float(num_unique_values) / num_total_values < 0.5:\n",
    "                dtype = \"category\"\n",
    "            else:\n",
    "                dtype = \"string\"\n",
    "            df[col] = df[col].astype(dtype)        \n",
    "        else:\n",
    "            df[col] = pd.to_datetime(df[col]).dt.date\n",
    "    return df\n",
    "\n",
    "\n",
    "def df_optimize(df: pd.DataFrame, datetime_features: List[str] = [], exclude = None):\n",
    "    return optimize_floats(optimize_ints(optimize_objects(df, datetime_features, exclude), exclude), exclude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conex√£o com o banco de dados\n",
    "A fun√ß√£o a seguir √© um `wrapper` simples que utiliza o `pyodbc` para se conectar ao banco de dados base da Anatel e retorna o objeto da conex√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def connect_db():\n",
    "    \"\"\"Conecta ao Banco ANATELBDRO01 e retorna o 'cursor' (iterador) do Banco pronto para fazer itera√ß√µes\"\"\"\n",
    "    conn = pyodbc.connect(\n",
    "        \"Driver={ODBC Driver 17 for SQL Server};\"\n",
    "        \"Server=ANATELBDRO01;\"\n",
    "        \"Database=SITARWEB;\"\n",
    "        \"Trusted_Connection=yes;\"\n",
    "        \"MultipleActiveResultSets=True;\",\n",
    "        timeout=TIMEOUT,\n",
    "    )\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow\n",
    "def test_connection():\n",
    "    conn = connect_db()\n",
    "    cursor = conn.cursor()\n",
    "    for query in (RADCOM, STEL):\n",
    "        cursor.execute(query)\n",
    "        test_eq(type(cursor.fetchone()), pyodbc.Row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fun√ß√µes auxiliares de Formata√ß√£o\n",
    "As fun√ß√µes a seguir s√£o utilizadas para formatar diversos objetos intermedi√°rios utilizados nas fun√ß√µes de leitura e atualiza√ß√£o da base de dados e n√£o s√£o chamadas diretamente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "def row2dict(row):\n",
    "    \"\"\"Receives a json row and return the dictionary from it\"\"\"\n",
    "    return {k: v for k, v in row.items()}\n",
    "\n",
    "\n",
    "def dict2cols(df, reject=()):\n",
    "    \"\"\"Recebe um dataframe com dicion√°rios nas c√©lulas e extrai os dicion√°rios como colunas\n",
    "    Opcionalmente ignora e exclue as colunas em reject\n",
    "    \"\"\"\n",
    "    for column in df.columns:\n",
    "        if column in reject:\n",
    "            df.drop(column, axis=1, inplace=True)\n",
    "            continue\n",
    "        if type(df[column].iloc[0]) == collections.OrderedDict:\n",
    "            try:\n",
    "                new_df = pd.DataFrame(df[column].apply(row2dict).tolist())\n",
    "                df = pd.concat([df, new_df], axis=1)\n",
    "                df.drop(column, axis=1, inplace=True)\n",
    "            except AttributeError:\n",
    "                continue\n",
    "    return df\n",
    "\n",
    "\n",
    "def parse_plano_basico(row, cols=COL_PB):\n",
    "    \"\"\"Receives a json row and filter the column in `cols`\"\"\"\n",
    "    return {k: row[k] for k in cols}\n",
    "\n",
    "\n",
    "def scrape_dataframe(id_list):\n",
    "    df = pd.DataFrame()\n",
    "    for id_ in track(id_list, description=\"Baixando informa√ß√µes complementares da Web\"):\n",
    "        html = requests.get(ESTACAO.format(id_))\n",
    "        df = df.append(pd.read_html(Soup(html.text).find(\"table\").html)[0])\n",
    "    \n",
    "    df.rename(columns={'NumFistel': 'Fistel',\n",
    "                       'Num Servi√ßo': 'Num_Servi√ßo'}, inplace=True)\n",
    "    return df[[\"Status\", \"Entidade\", \"Fistel\", \"Frequ√™ncia\", \"Classe\", 'Num_Servi√ßo', 'Munic√≠pio', 'UF']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "def clean_merge(pasta, df):\n",
    "    df = df.copy()\n",
    "    COLS = [c for c in df.columns if \"_x\" in c]\n",
    "    for col in COLS:\n",
    "        col_x = col\n",
    "        col_y = col.split(\"_\")[0] + \"_y\"\n",
    "        if df[col_x].count() > df[col_y].count():\n",
    "            a, b = col_x, col_y\n",
    "        else:\n",
    "            a, b = col_y, col_x\n",
    "\n",
    "        df.loc[df[a].isna(), a] = df.loc[df[a].isna(), b]\n",
    "        df.drop(b, axis=1, inplace=True)\n",
    "        df.rename({a: a[:-2]}, axis=1, inplace=True)\n",
    "\n",
    "    df.loc[df.Latitude_Transmissor == \"\", \"Latitude_Transmissor\"] = df.loc[\n",
    "        df.Latitude_Transmissor == \"\", \"Latitude_Esta√ß√£o\"\n",
    "    ]\n",
    "    df.loc[df.Longitude_Transmissor == \"\", \"Longitude_Transmissor\"] = df.loc[\n",
    "        df.Longitude_Transmissor == \"\", \"Longitude_Esta√ß√£o\"\n",
    "    ]\n",
    "    df.loc[df.Latitude_Transmissor.isna(), \"Latitude_Transmissor\"] = df.loc[\n",
    "        df.Latitude_Transmissor.isna(), \"Latitude_Esta√ß√£o\"\n",
    "    ]\n",
    "    df.loc[df.Longitude_Transmissor.isna(), \"Longitude_Transmissor\"] = df.loc[\n",
    "        df.Longitude_Transmissor.isna(), \"Longitude_Esta√ß√£o\"\n",
    "    ]\n",
    "    df.drop([\"Latitude_Esta√ß√£o\", \"Longitude_Esta√ß√£o\"], axis=1, inplace=True)\n",
    "    df.rename(\n",
    "        columns={\n",
    "            \"Latitude_Transmissor\": \"Latitude\",\n",
    "            \"Longitude_Transmissor\": \"Longitude\",\n",
    "        },\n",
    "        inplace=True,\n",
    "    )\n",
    "    municipios = Path(f\"{pasta}/munic√≠pios.fth\")\n",
    "    if not municipios.exists():\n",
    "        municipios = Path(f\"{pasta}/munic√≠pios.xlsx\")\n",
    "        if not municipios.exists():\n",
    "            raise FileNotFoundError(f\"√â necessario a tabela de munic√≠pios munic√≠pios.fth | munic√≠pios.xlsx na pasta {pasta}\")\n",
    "        m = pd.read_excel(municipios, engine='openpyxl')\n",
    "    else:\n",
    "        m = pd.read_feather(municipios)\n",
    "    m.loc[\n",
    "        m.Munic√≠pio == \"Sant'Ana do Livramento\", \"Munic√≠pio\"\n",
    "    ] = \"Santana do Livramento\"\n",
    "    m[\"Munic√≠pio\"] = (\n",
    "        m.Munic√≠pio.apply(unidecode).str.lower().str.replace(\"'\", \" \")\n",
    "    )  # (lambda x: \"\".join(e for e in x if e.isalnum()))\n",
    "    m[\"UF\"] = m.UF.str.lower()\n",
    "    df[\"Coordenadas_do_Munic√≠pio\"] = False\n",
    "    df[\"Latitude\"] = df.Latitude.str.replace(\",\", \".\")\n",
    "    df[\"Longitude\"] = df.Longitude.str.replace(\",\", \".\")\n",
    "    df[\"Frequ√™ncia\"] = df.Frequ√™ncia.str.replace(\",\", \".\")\n",
    "    df.loc[df[\"Munic√≠pio\"] == \"Poxor√©o\", \"Munic√≠pio\"] = \"Poxor√©u\"\n",
    "    df.loc[df[\"Munic√≠pio\"] == \"Couto de Magalh√£es\", \"Munic√≠pio\"] = \"Couto Magalh√£es\"\n",
    "    for row in df[(df.Latitude == \"\") | (df.Latitude.isna())].itertuples():\n",
    "        try:\n",
    "            left = unidecode(row.Munic√≠pio).lower()\n",
    "            m_coord = (\n",
    "                m.loc[\n",
    "                    (m.Munic√≠pio == left) & (m.UF == row.UF.lower()),\n",
    "                    [\"Latitude\", \"Longitude\"],\n",
    "                ]\n",
    "                .values.flatten()\n",
    "                .tolist()\n",
    "            )\n",
    "            df.loc[row.Index, \"Latitude\"] = m_coord[0]\n",
    "            df.loc[row.Index, \"Longitude\"] = m_coord[1]\n",
    "            df.loc[row.Index, \"Coordenadas_do_Munic√≠pio\"] = True\n",
    "        except ValueError:\n",
    "            print(left, row.UF, m_coord)\n",
    "            continue\n",
    "\n",
    "    freq_nans = df[df.Frequ√™ncia.isna()].Id.tolist()\n",
    "    complement_df = scrape_dataframe(freq_nans)\n",
    "    df.loc[\n",
    "        df.Frequ√™ncia.isna(), [\"Status\", \"Entidade\", \"Fistel\", \"Frequ√™ncia\", \"Classe\", \n",
    "                               'Num_Servi√ßo', 'Munic√≠pio', 'UF']\n",
    "        ] = complement_df.values\n",
    "        \n",
    "    for r in df[(df.Entidade.isna()) | (df.Entidade == '')].itertuples():\n",
    "        df.loc[r.Index, 'Entidade'] = ENTIDADES.get(r.Fistel, '')\n",
    "\n",
    "    df.loc[df[\"N√∫mero_da_Esta√ß√£o\"] == \"\", \"N√∫mero_da_Esta√ß√£o\"] = -1\n",
    "    df[\"Latitude\"] = df[\"Latitude\"].astype(\"float\")\n",
    "    df[\"Longitude\"] = df[\"Longitude\"].astype(\"float\")\n",
    "    df[\"Frequ√™ncia\"] = df.Frequ√™ncia.astype(\"float\")\n",
    "    df.loc[df.Servi√ßo == 'OM', 'Frequ√™ncia'] = df.loc[df.Servi√ßo == 'OM', 'Frequ√™ncia'].apply(lambda x: Decimal(x) / Decimal(1000))\n",
    "    df[\"Frequ√™ncia\"] = df.Frequ√™ncia.astype(\"float\")\n",
    "    df['Validade_RF'] = df.Validade_RF.astype('string').str.slice(0,10)\n",
    "    df.loc[df['Num_Ato'] == '', 'Num_Ato'] = -1\n",
    "    df['Num_Ato'] = df.Num_Ato.astype('int')\n",
    "    return df_optimize(df, exclude=['Latitude', 'Longitude', 'Frequ√™ncia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "def read_esta√ß√µes(path):\n",
    "    def extrair_ato(row):\n",
    "        if not isinstance(row, str):\n",
    "            row = listify(row)[::-1]\n",
    "            for d in row:\n",
    "                if not isinstance(d, dict):\n",
    "                    continue\n",
    "                if (d.get(\"@TipoDocumento\") == \"Ato\") and (\n",
    "                    d.get(\"@Razao\") == \"Autoriza o Uso de Radiofrequ√™ncia\"\n",
    "                ):\n",
    "                    return d[\"@NumDocumento\"], d[\"@DataDOU\"][:10]\n",
    "            else:\n",
    "                return \"\", \"\"\n",
    "        return \"\", \"\"\n",
    "\n",
    "    es = pdx.read_xml(path, [\"estacao_rd\"])\n",
    "    dfs = []\n",
    "    for i in range(es.shape[0]):\n",
    "        df = pd.DataFrame(es[\"row\"][i]).replace(\"\", pd.NA)\n",
    "        df = dict2cols(df)\n",
    "        df.columns = [unidecode(c).lower().replace(\"@\", \"\") for c in df.columns]\n",
    "        dfs.append(df)\n",
    "    df = pd.concat(dfs)\n",
    "    df = df[df.state.str.contains(\"-C1$|-C2$|-C3$|-C4$|-C7|-C98$\")].reset_index(drop=True)\n",
    "    docs = L(df.historico_documentos.apply(extrair_ato).tolist())\n",
    "    return df\n",
    "    df = df.loc[:, COL_ESTACOES]\n",
    "    df[\"Num_Ato\"] = docs.itemgot(0).map(str)\n",
    "    df[\"Data_Ato\"] = docs.itemgot(1).map(str)\n",
    "    df.columns = NEW_ESTACOES\n",
    "    df['Validade_RF'] = df.Validade_RF.astype('str').str.slice(0,10)\n",
    "    df[\"Data_Ato\"] = df.Data_Ato.str.slice(0,10)\n",
    "    df['Entidade'] = df.Entidade.fillna('')\n",
    "    ENTIDADES.update({r.Fistel : r.Entidade for r in df.itertuples() if r.Entidade != ''})\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_plano_basico(path):\n",
    "    pb = pdx.read_xml(path, [\"plano_basico\"])\n",
    "    # df = pd.DataFrame(df[\"row\"].apply(row2dict).tolist()).replace(\"\", pd.NA)\n",
    "    dfs = []\n",
    "    for i in range(pb.shape[0]):\n",
    "        df = pd.DataFrame(pb[\"row\"][i]).replace(\"\", pd.NA)\n",
    "        df = dict2cols(df)\n",
    "        df.columns = [unidecode(c).lower().replace(\"@\", \"\") for c in df.columns]\n",
    "        dfs.append(df)\n",
    "    df = pd.concat(dfs)\n",
    "    df = df.loc[df.pais == \"BRA\", COL_PB].reset_index(drop=True)\n",
    "    df.columns = NEW_PB\n",
    "    df.sort_values([\"Id\", \"Canal\"], inplace=True)\n",
    "    df['Entidade'] = df.Entidade.fillna('')\n",
    "    ENTIDADES.update({r.Fistel : r.Entidade for r in df.itertuples() if r.Entidade != ''})\n",
    "    df = df.groupby(\"Id\", as_index=False).first()  # remove duplicated with NaNs\n",
    "    df.dropna(subset=['Status'], inplace=True)\n",
    "    df = df[df.Status.str.contains(\"-C1$|-C2$|-C3$|-C4$|-C7|-C98$\")].reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def read_historico(path):\n",
    "    regex = r\"\\s([a-zA-Z]+)=\\'{1}([\\w\\-\\ :\\.]*)\\'{1}\"\n",
    "    with ZipFile(path) as xmlzip:\n",
    "        with xmlzip.open(\"documento_historicos.xml\", \"r\") as xml:\n",
    "            xml_list = xml.read().decode().split(\"\\n\")[2:-1]\n",
    "    dict_list = []\n",
    "    for item in xml_list:\n",
    "        matches = re.finditer(regex, item, re.MULTILINE)\n",
    "        dict_list.append(dict(match.groups() for match in matches))\n",
    "    df = pd.DataFrame(dict_list)\n",
    "    df = df[\n",
    "        (df.tipoDocumento == \"Ato\") & (df.razao == \"Autoriza o Uso de Radiofrequ√™ncia\")\n",
    "    ].reset_index()\n",
    "    df = df.loc[:, [\"id\", \"numeroDocumento\", \"orgao\", \"dataDocumento\"]]\n",
    "    df.columns = [\"Id\", \"Num_Ato\", \"√ìrgao\", \"Data_Ato\"]\n",
    "    df[\"Data_Ato\"] = pd.to_datetime(df.Data_Ato)\n",
    "    return df.sort_values(\"Data_Ato\").groupby(\"Id\").last().reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atualiza√ß√£o das bases de dados\n",
    "As bases de dados s√£o atualizadas atr√°ves das fun√ß√µes a seguir, o √∫nico argumento passado em todas elas √© a pasta na qual os arquivos locais processados ser√£o salvos, os nomes dos arquivos s√£o padronizados e n√£o podem ser editados para que as fun√ß√µes de leitura e processamento recebam somente a pasta na qual esses arquivos foram salvos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def update_radcom(pasta):\n",
    "    \"\"\"Atualiza a tabela local retornada pela query `RADCOM`\"\"\"\n",
    "    with console.status(\n",
    "        \"[cyan]Lendo o Banco de Dados de Radcom...\", spinner=\"earth\"\n",
    "    ) as status:\n",
    "        try:\n",
    "            conn = connect_db()\n",
    "            df = pd.read_sql_query(RADCOM, conn)\n",
    "            df = df_optimize(df, exclude=['Frequ√™ncia'])\n",
    "            try:\n",
    "                df.to_feather(f\"{pasta}/radcom.fth\")\n",
    "            except ArrowInvalid:\n",
    "                df.to_excel(f\"{pasta}/radcom.xlsx\", engine='openpyxl', index=False)\n",
    "        except pyodbc.OperationalError:\n",
    "            status.console.log(\n",
    "                \"N√£o foi poss√≠vel abrir uma conex√£o com o SQL Server. Esta conex√£o somente funciona da rede cabeada!\"\n",
    "            )\n",
    "\n",
    "\n",
    "def update_stel(pasta):\n",
    "    \"\"\"Atualiza a tabela local retornada pela query `STEL`\"\"\"\n",
    "    with console.status(\n",
    "        \"[magenta]Lendo o Banco de Dados do STEL. Processo Lento, aguarde...\",\n",
    "        spinner=\"moon\",\n",
    "    ) as status:\n",
    "        try:\n",
    "            conn = connect_db()\n",
    "            df = pd.read_sql_query(STEL, conn)\n",
    "            df['Validade_RF'] = df.Validade_RF.astype('str').str.slice(0,10)\n",
    "            df = df_optimize(df, exclude=['Frequ√™ncia'])\n",
    "            try:\n",
    "                df.to_feather(f\"{pasta}/stel.fth\")\n",
    "            except ArrowInvalid:\n",
    "                df.to_excel(f\"{pasta}/stel.xlsx\", engine='openpyxl', index=False)\n",
    "        except pyodbc.OperationalError:\n",
    "            status.console.log(\n",
    "                \"N√£o foi poss√≠vel abrir uma conex√£o com o SQL Server. Esta conex√£o somente funciona da rede cabeada!\"\n",
    "            )\n",
    "\n",
    "\n",
    "def update_mosaico(pasta):\n",
    "    \"\"\"Atualiza a tabela local do Mosaico. √â baixado e processado arquivos xml zipados da p√°gina p√∫blica do Spectrum E\"\"\"\n",
    "    with console.status(\n",
    "        \"[blue]Baixando as Esta√ß√µes do Mosaico...\", spinner=\"shark\"\n",
    "    ) as status:\n",
    "        file = requests.get(ESTACOES)\n",
    "        with open(f\"{pasta}/esta√ß√µes.zip\", \"wb\") as esta√ß√µes:\n",
    "            esta√ß√µes.write(file.content)\n",
    "    with console.status(\n",
    "        \"[blue]Baixando o Plano B√°sico das Esta√ß√µes...\", spinner=\"weather\"\n",
    "    ) as status:\n",
    "        file = requests.get(PLANO_BASICO)\n",
    "        with open(f\"{pasta}/Canais.zip\", \"wb\") as plano_basico:\n",
    "            plano_basico.write(file.content)\n",
    "    console.print(\":package: [blue]Consolidando as bases de dados...\")\n",
    "    esta√ß√µes = read_esta√ß√µes(f\"{pasta}/esta√ß√µes.zip\")\n",
    "    plano_basico = read_plano_basico(f\"{pasta}/Canais.zip\")\n",
    "    df = esta√ß√µes.merge(plano_basico, on=\"Id\", how=\"left\")\n",
    "    df = clean_merge(pasta, df)\n",
    "    try:\n",
    "        df.reset_index(drop=True).to_feather(f\"{pasta}/mosaico.fth\")\n",
    "    except ArrowInvalid:\n",
    "        with pd.ExcelWriter(f\"{pasta}/mosaico.xlsx\") as workbook:\n",
    "            df.reset_index(drop=True).to_excel(workbook, sheet_name='Sheet1', engine=\"openpyxl\", index=False)\n",
    "    console.print(\"Kb√¥ :vampire:\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def update_base(pasta, up_stel=False, up_radcom=False, up_mosaico=False):\n",
    "    \"\"\"Wrapper que atualiza opcionalmente l√™ e atualiza as tr√™s bases indicadas anteriormente, as combina e salva o arquivo consolidado na pasta `pasta`\"\"\"\n",
    "    stel = read_stel(pasta, up_stel).loc[:, TELECOM]\n",
    "    stel.rename(\n",
    "        columns={\"Servi√ßo\": \"Num_Servi√ßo\", \"N√∫mero da Esta√ß√£o\": \"N√∫mero_da_Esta√ß√£o\"},\n",
    "        inplace=True,\n",
    "    )\n",
    "    radcom = read_radcom(pasta, up_radcom)\n",
    "    radcom.rename(columns={\"N√∫mero da Esta√ß√£o\": \"N√∫mero_da_Esta√ß√£o\"}, inplace=True)\n",
    "    mosaico = read_mosaico(pasta, up_mosaico)\n",
    "    radcom[\"Num_Servi√ßo\"] = 231\n",
    "    radcom[\"Status\"] = \"RADCOM\"\n",
    "    radcom[\"Classe\"] = radcom.Fase.str.strip() + \"-\" + radcom.Situa√ß√£o.str.strip()\n",
    "    radcom[\"Entidade\"] = radcom.Entidade.str.rstrip().str.lstrip()\n",
    "    radcom[\"Num_Ato\"] = -1\n",
    "    radcom[\"Data_Ato\"] = \"\"\n",
    "    radcom[\"Validade_RF\"] = \"\"\n",
    "    radcom = radcom.loc[:, RADIODIFUSAO]\n",
    "    stel[\"Num_Ato\"] = -1\n",
    "    stel[\"Data_Ato\"] = \"\"\n",
    "    stel['Entidade'] = stel.Entidade.str.rstrip().str.lstrip()\n",
    "    mosaico = mosaico.loc[:, RADIODIFUSAO]\n",
    "    rd = mosaico.append(radcom)\n",
    "    rd = rd.append(stel).sort_values(\"Frequ√™ncia\").reset_index(drop=True)\n",
    "    rd = df_optimize(rd, exclude=['Frequ√™ncia'])\n",
    "    try:\n",
    "        rd.to_feather(f\"{pasta}/base.fth\")\n",
    "    except ArrowInvalid:\n",
    "        with pd.ExcelWriter(f\"{pasta}/base.xlsx\") as workbook:\n",
    "            rd.to_excel(workbook, sheet_name='Sheet1', engine=\"openpyxl\", index=False)\n",
    "    return rd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fun√ß√µes de Leitura das diversas bases\n",
    "A presente biblioteca utiliza tr√™s bases de dados: \n",
    "* `STEL` - Servi√ßos Privados de Telecomunica√ß√µes\n",
    "* `RADCOM` - Servi√ßo de Radiodifus√£o comunit√°ria\n",
    "* `MOSAICO` - Demais servi√ßos de Radiodifus√£o e paulatinamente tamb√©m adicionado servi√ßos privados\n",
    "\n",
    "As fun√ß√µes a seguir s√£o para leitura dos arquivos locais baixados e processados dessas bases, opcionalmente esses arquivos podem ser atualizados antes de serem lidos passando o argumento `update = True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def read_stel(pasta, update=False):\n",
    "    \"\"\"L√™ o banco de dados salvo localmente do STEL. Opcionalmente o atualiza pelo Banco de Dados ANATELBDRO01 caso `update = True` ou n√£o exista o arquivo local\"\"\"\n",
    "    if update:\n",
    "        update_stel(pasta)\n",
    "    file = Path(f\"{pasta}/stel.fth\")\n",
    "    try:\n",
    "        stel = pd.read_feather(file)\n",
    "    except (ArrowInvalid, FileNotFoundError):\n",
    "        file = Path(f\"{pasta}/stel.xlsx\")\n",
    "        try:\n",
    "            stel = pd.read_excel(file, engine=\"openpyxl\")\n",
    "        except FileNotFoundError:\n",
    "            read_stel(pasta, True)\n",
    "    return stel\n",
    "\n",
    "\n",
    "def read_radcom(pasta, update=False):\n",
    "    \"\"\"L√™ o banco de dados salvo localmente de RADCOM. Opcionalmente o atualiza pelo Banco de Dados ANATELBDRO01 caso `update = True` ou n√£o exista o arquivo local\"\"\"\n",
    "    if update:\n",
    "        update_radcom(pasta)\n",
    "    file = Path(f\"{pasta}/radcom.fth\")\n",
    "    try:\n",
    "        radcom = pd.read_feather(file)\n",
    "    except (ArrowInvalid, FileNotFoundError):\n",
    "        file = Path(f\"{pasta}/radcom.xlsx\")\n",
    "        try:\n",
    "            radcom = pd.read_excel(file, engine=\"openpyxl\")\n",
    "        except FileNotFoundError:\n",
    "            read_radcom(pasta, True)\n",
    "    return radcom\n",
    "\n",
    "\n",
    "def read_mosaico(pasta, update=False):\n",
    "    \"\"\"L√™ o banco de dados salvo localmente do MOSAICO. Opcionalmente o atualiza antes da leitura baixando os diversos arquivos dispon√≠veis na interface web p√∫blica\"\"\"\n",
    "    if update:\n",
    "        update_mosaico(pasta)\n",
    "    file = Path(f\"{pasta}/mosaico.fth\")\n",
    "    try:\n",
    "        df = pd.read_feather(file)\n",
    "    except (ArrowInvalid, FileNotFoundError):\n",
    "        file = Path(f\"{pasta}/mosaico.xlsx\")\n",
    "        try:\n",
    "            df = pd.read_excel(file)\n",
    "        except FileNotFoundError:\n",
    "            return read_mosaico(pasta, update=True)\n",
    "    return df_optimize(df, exclude=['Frequ√™ncia'])\n",
    "    \n",
    "\n",
    "def read_base(pasta, up_stel=False, up_radcom=False, up_mosaico=False):\n",
    "    \"\"\"Wrapper que combina a chamada das tr√™s fun√ß√µes de leitura do banco e opcionalmente √© poss√≠vel atualiz√°-las antes da leitura\"\"\"\n",
    "    if any([up_stel, up_radcom, up_mosaico]):\n",
    "        update_base(pasta, up_stel, up_radcom, up_mosaico)\n",
    "    file = Path(f\"{pasta}/base.fth\")\n",
    "    try:\n",
    "        df =  pd.read_feather(file)\n",
    "    except (ArrowInvalid, FileNotFoundError):\n",
    "        file = Path(f\"{pasta}/base.xlsx\")\n",
    "        try:\n",
    "            df = pd.read_excel(file, engine='openpyxl')\n",
    "        except FileNotFoundError:\n",
    "            df = update_base(pasta, up_stel, up_radcom, up_mosaico)\n",
    "    return df_optimize(df, exclude=['Frequ√™ncia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasta = r'G:\\Meu Drive\\repos\\Code\\BaseDados'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">üåï </span> <span style=\"color: #800080; text-decoration-color: #800080\">Lendo o Banco de Dados do STEL. Processo Lento, aguarde...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32müåï \u001b[0m \u001b[35mLendo o Banco de Dados do STEL. Processo Lento, aguarde...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stel = read_stel(pasta, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stel.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radcom = read_radcom(pasta, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radcom.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaico = read_mosaico(pasta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaico.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = read_base(pasta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequ√™ncia</th>\n",
       "      <th>Num_Servi√ßo</th>\n",
       "      <th>Status</th>\n",
       "      <th>Classe</th>\n",
       "      <th>Entidade</th>\n",
       "      <th>Fistel</th>\n",
       "      <th>N√∫mero_da_Esta√ß√£o</th>\n",
       "      <th>Munic√≠pio</th>\n",
       "      <th>UF</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Validade_RF</th>\n",
       "      <th>Num_Ato</th>\n",
       "      <th>Data_Ato</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104257</th>\n",
       "      <td>157.73125</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RUMO MALHA CENTRAL S.A.</td>\n",
       "      <td>50418927251</td>\n",
       "      <td>1010234894</td>\n",
       "      <td>Santa Isabel</td>\n",
       "      <td>GO</td>\n",
       "      <td>-15.324844</td>\n",
       "      <td>-49.376007</td>\n",
       "      <td>2040-02-07</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369472</th>\n",
       "      <td>459.83750</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LIDERSUL SEGURANCA PRIVADA EIRELI</td>\n",
       "      <td>50416383734</td>\n",
       "      <td>1006689653</td>\n",
       "      <td>S√£o Jos√© dos Pinhais</td>\n",
       "      <td>PR</td>\n",
       "      <td>-25.544958</td>\n",
       "      <td>-49.206837</td>\n",
       "      <td>2038-05-15</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253982</th>\n",
       "      <td>168.23125</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POLICIA MILITAR DO ESTADO DE MINAS GERAIS</td>\n",
       "      <td>50401288943</td>\n",
       "      <td>1004062220</td>\n",
       "      <td>Santa Luzia</td>\n",
       "      <td>MG</td>\n",
       "      <td>-19.796352</td>\n",
       "      <td>-43.919338</td>\n",
       "      <td>2037-06-16</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405362</th>\n",
       "      <td>932.56250</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CEMIG DISTRIBUICAO S.A</td>\n",
       "      <td>50402659058</td>\n",
       "      <td>683549049</td>\n",
       "      <td>Ribeir√£o das Neves</td>\n",
       "      <td>MG</td>\n",
       "      <td>-19.747778</td>\n",
       "      <td>-44.146946</td>\n",
       "      <td>2030-11-08</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230015</th>\n",
       "      <td>167.85625</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POLICIA MILITAR DO ESTADO DE MINAS GERAIS</td>\n",
       "      <td>50401288943</td>\n",
       "      <td>1007982516</td>\n",
       "      <td>Concei√ß√£o do Mato Dentro</td>\n",
       "      <td>MG</td>\n",
       "      <td>-19.034672</td>\n",
       "      <td>-43.423973</td>\n",
       "      <td>2037-06-16</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316436</th>\n",
       "      <td>383.22500</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONCESSIONARIA DO SISTEMA ANHANGUERA-BANDEIRAN...</td>\n",
       "      <td>50001442015</td>\n",
       "      <td>430890052</td>\n",
       "      <td>Jundia√≠</td>\n",
       "      <td>SP</td>\n",
       "      <td>-23.242525</td>\n",
       "      <td>-46.902634</td>\n",
       "      <td>2038-08-17</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21242</th>\n",
       "      <td>148.03000</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AGRICOLA MORENO DE NIPO√É LTDA</td>\n",
       "      <td>50411773844</td>\n",
       "      <td>695281321</td>\n",
       "      <td>Monte Apraz√≠vel</td>\n",
       "      <td>SP</td>\n",
       "      <td>-20.687666</td>\n",
       "      <td>-49.689304</td>\n",
       "      <td>2041-04-15</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309160</th>\n",
       "      <td>368.58750</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GERDAU A√áOMINAS S/A</td>\n",
       "      <td>4030000843</td>\n",
       "      <td>698419316</td>\n",
       "      <td>Congonhas</td>\n",
       "      <td>MG</td>\n",
       "      <td>-20.543436</td>\n",
       "      <td>-43.741840</td>\n",
       "      <td>2023-07-16</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85198</th>\n",
       "      <td>156.57500</td>\n",
       "      <td>604</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IPIRANGA PRODUTOS DE PETROLEO S.A.</td>\n",
       "      <td>50415298091</td>\n",
       "      <td>1010898679</td>\n",
       "      <td>Itaituba</td>\n",
       "      <td>PA</td>\n",
       "      <td>-4.294445</td>\n",
       "      <td>-56.018890</td>\n",
       "      <td>2037-10-06</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22515</th>\n",
       "      <td>148.11000</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SAO MARTINHO S/A</td>\n",
       "      <td>2030099406</td>\n",
       "      <td>522969917</td>\n",
       "      <td>Iracem√°polis</td>\n",
       "      <td>SP</td>\n",
       "      <td>-22.585897</td>\n",
       "      <td>-47.531334</td>\n",
       "      <td>2027-02-12</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Frequ√™ncia  Num_Servi√ßo Status Classe  \\\n",
       "104257   157.73125           19    NaN    NaN   \n",
       "369472   459.83750           19    NaN    NaN   \n",
       "253982   168.23125           19    NaN    NaN   \n",
       "405362   932.56250           19    NaN    NaN   \n",
       "230015   167.85625           19    NaN    NaN   \n",
       "316436   383.22500           19    NaN    NaN   \n",
       "21242    148.03000           19    NaN    NaN   \n",
       "309160   368.58750           19    NaN    NaN   \n",
       "85198    156.57500          604    NaN    NaN   \n",
       "22515    148.11000           19    NaN    NaN   \n",
       "\n",
       "                                                 Entidade       Fistel  \\\n",
       "104257                            RUMO MALHA CENTRAL S.A.  50418927251   \n",
       "369472                  LIDERSUL SEGURANCA PRIVADA EIRELI  50416383734   \n",
       "253982          POLICIA MILITAR DO ESTADO DE MINAS GERAIS  50401288943   \n",
       "405362                             CEMIG DISTRIBUICAO S.A  50402659058   \n",
       "230015          POLICIA MILITAR DO ESTADO DE MINAS GERAIS  50401288943   \n",
       "316436  CONCESSIONARIA DO SISTEMA ANHANGUERA-BANDEIRAN...  50001442015   \n",
       "21242                       AGRICOLA MORENO DE NIPO√É LTDA  50411773844   \n",
       "309160                                GERDAU A√áOMINAS S/A   4030000843   \n",
       "85198                  IPIRANGA PRODUTOS DE PETROLEO S.A.  50415298091   \n",
       "22515                                    SAO MARTINHO S/A   2030099406   \n",
       "\n",
       "        N√∫mero_da_Esta√ß√£o                 Munic√≠pio  UF   Latitude  Longitude  \\\n",
       "104257         1010234894              Santa Isabel  GO -15.324844 -49.376007   \n",
       "369472         1006689653      S√£o Jos√© dos Pinhais  PR -25.544958 -49.206837   \n",
       "253982         1004062220               Santa Luzia  MG -19.796352 -43.919338   \n",
       "405362          683549049        Ribeir√£o das Neves  MG -19.747778 -44.146946   \n",
       "230015         1007982516  Concei√ß√£o do Mato Dentro  MG -19.034672 -43.423973   \n",
       "316436          430890052                   Jundia√≠  SP -23.242525 -46.902634   \n",
       "21242           695281321           Monte Apraz√≠vel  SP -20.687666 -49.689304   \n",
       "309160          698419316                 Congonhas  MG -20.543436 -43.741840   \n",
       "85198          1010898679                  Itaituba  PA  -4.294445 -56.018890   \n",
       "22515           522969917              Iracem√°polis  SP -22.585897 -47.531334   \n",
       "\n",
       "       Validade_RF  Num_Ato Data_Ato  \n",
       "104257  2040-02-07       -1      NaN  \n",
       "369472  2038-05-15       -1      NaN  \n",
       "253982  2037-06-16       -1      NaN  \n",
       "405362  2030-11-08       -1      NaN  \n",
       "230015  2037-06-16       -1      NaN  \n",
       "316436  2038-08-17       -1      NaN  \n",
       "21242   2041-04-15       -1      NaN  \n",
       "309160  2023-07-16       -1      NaN  \n",
       "85198   2037-10-06       -1      NaN  \n",
       "22515   2027-02-12       -1      NaN  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 433838 entries, 0 to 433837\n",
      "Data columns (total 14 columns):\n",
      " #   Column             Non-Null Count   Dtype   \n",
      "---  ------             --------------   -----   \n",
      " 0   Frequ√™ncia         433838 non-null  float64 \n",
      " 1   Num_Servi√ßo        433838 non-null  int16   \n",
      " 2   Status             28147 non-null   category\n",
      " 3   Classe             28122 non-null   category\n",
      " 4   Entidade           433827 non-null  category\n",
      " 5   Fistel             433838 non-null  int64   \n",
      " 6   N√∫mero_da_Esta√ß√£o  433838 non-null  int32   \n",
      " 7   Munic√≠pio          433838 non-null  category\n",
      " 8   UF                 433838 non-null  category\n",
      " 9   Latitude           433838 non-null  float32 \n",
      " 10  Longitude          433838 non-null  float32 \n",
      " 11  Validade_RF        427003 non-null  category\n",
      " 12  Num_Ato            433838 non-null  int32   \n",
      " 13  Data_Ato           13171 non-null   category\n",
      "dtypes: category(7), float32(2), float64(1), int16(1), int32(2), int64(1)\n",
      "memory usage: 19.8 MB\n"
     ]
    }
   ],
   "source": [
    "base.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.to_feather(f'{pasta}/base.fth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted constants.ipynb.\n",
      "Converted filter.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted queries.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anateldb]",
   "language": "python",
   "name": "conda-env-anateldb-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
